{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossentropy method\n",
    "\n",
    "This notebook will teach you to solve reinforcement learning problems with crossentropy method. We'll follow-up by scaling everything up and using neural network policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pip install box2d-py -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict as ddict\n",
    "import sklearn\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import gym.wrappers\n",
    "from IPython.display import HTML\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In google collab, uncomment this:\n",
    "# !wget https://bit.ly/2FMJP5K -O setup.py && bash setup.py\n",
    "\n",
    "# XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY = : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "env = gym.make(\"Taxi-v2\")\n",
    "env.reset()\n",
    "env.render()\n",
    "\n",
    "n_states = env.observation_space.n\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "print(\"n_states=%i, n_actions=%i\" % (n_states, n_actions))\n",
    "'''\n",
    "n_states, n_actions = 500, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossentropy method steps (2pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digging deeper: approximate crossentropy with neural nets\n",
    "\n",
    "![img](https://casd35.wikispaces.com/file/view/digging_deeper_final.jpg/359658499/503x260/digging_deeper_final.jpg)\n",
    "\n",
    "In this section we will train a neural network policy for continuous state space game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(elite_states, elite_actions):\n",
    "    \"\"\"\n",
    "    Given old policy and a list of elite states/actions from select_elites,\n",
    "    return new updated policy where each action probability is proportional to\n",
    "\n",
    "    policy[s_i,a_i] ~ #[occurences of si and ai in elite states/actions]\n",
    "\n",
    "    Don't forget to normalize policy to get valid probabilities and handle 0/0 case.\n",
    "    In case you never visited a state, set probabilities for all actions to 1./n_actions\n",
    "\n",
    "    :param elite_states: 1D list of states from elite sessions\n",
    "    :param elite_actions: 1D list of actions from elite sessions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    new_policy = np.zeros([n_states, n_actions])\n",
    "\n",
    "    # <Your code here: update probabilities for actions given elite states & actions >\n",
    "    # Don't forget to set 1/n_actions for all actions in unvisited states.\n",
    "    state_action_dict = ddict(lambda: np.zeros(n_actions))\n",
    "    for i in range(len(elite_states)):\n",
    "        state_action_dict[elite_states[i]][elite_actions[i]] += 1\n",
    "        \n",
    "    for i in range(n_states):\n",
    "        if i not in state_action_dict:\n",
    "            new_policy[i] = np.ones(n_actions) / n_actions\n",
    "        else:\n",
    "            new_policy[i] = state_action_dict[i] / state_action_dict[i].sum()\n",
    "\n",
    "    return new_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_progress(rewards_batch, log, reward_range=[-990, +10], percentile=None):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    # print(reward_range)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "               [0], [100], label=\"percentile\", color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i][t]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you're confused, see examples below. Please don't assume that states are integers (they'll get different later).\n",
    "    \"\"\"\n",
    "\n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "    \n",
    "    indexes = (rewards_batch >= reward_threshold)\n",
    "    # print(indexes)\n",
    "    # print(states_batch)\n",
    "    \n",
    "    elite_states = np.concatenate(states_batch[indexes], axis=0)\n",
    "    elite_actions = np.concatenate(actions_batch[indexes], axis=0)\n",
    "    \n",
    "    # print(elite_states)\n",
    "    return elite_states, elite_actions\n",
    "\n",
    "    elite_states = []\n",
    "    elite_actions = []\n",
    "    for i in range(len(states_batch)):\n",
    "        if rewards_batch[i] >= reward_threshold:\n",
    "            elite_states.extend(states_batch[i])\n",
    "            elite_actions.extend(actions_batch[i])\n",
    "\n",
    "\n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "elite_states, elite_actions = ([1, 2, 3, 4, 2, 0, 2, 3, 1], [\n",
    "                               0, 2, 4, 3, 2, 0, 1, 3, 3])\n",
    "\n",
    "\n",
    "new_policy = update_policy(elite_states, elite_actions)\n",
    "\n",
    "assert np.isfinite(new_policy).all(\n",
    "), \"Your new policy contains NaNs or +-inf. Make sure you don't divide by zero.\"\n",
    "assert np.all(\n",
    "    new_policy >= 0), \"Your new policy can't have negative action probabilities\"\n",
    "assert np.allclose(new_policy.sum(\n",
    "    axis=-1), 1), \"Your new policy should be a valid probability distribution over actions\"\n",
    "reference_answer = np.array([\n",
    "    [1.,  0.,  0.,  0.,  0.],\n",
    "    [0.5,  0.,  0.,  0.5,  0.],\n",
    "    [0.,  0.33333333,  0.66666667,  0.,  0.],\n",
    "    [0.,  0.,  0.,  0.5,  0.5]])\n",
    "assert np.allclose(new_policy[:4, :5], reference_answer)\n",
    "print(\"Ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok!\n"
     ]
    }
   ],
   "source": [
    "states_batch = [\n",
    "    [1, 2, 3],  # game1\n",
    "    [4, 2, 0, 2],  # game2\n",
    "    [3, 1]  # game3\n",
    "]\n",
    "\n",
    "\n",
    "actions_batch = [\n",
    "    [0, 2, 4],  # game1\n",
    "    [3, 2, 0, 1],  # game2\n",
    "    [3, 3]  # game3\n",
    "]\n",
    "rewards_batch = [\n",
    "    3,  # game1\n",
    "    4,  # game2\n",
    "    5,  # game3\n",
    "]\n",
    "\n",
    "states_batch = np.array(states_batch)\n",
    "actions_batch = np.array(actions_batch)\n",
    "rewards_batch = np.array(rewards_batch)\n",
    "\n",
    "\n",
    "test_result_0 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=0)\n",
    "test_result_40 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=30)\n",
    "test_result_90 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=90)\n",
    "test_result_100 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=100)\n",
    "\n",
    "assert np.all(test_result_0[0] == [1, 2, 3, 4, 2, 0, 2, 3, 1])  \\\n",
    "    and np.all(test_result_0[1] == [0, 2, 4, 3, 2, 0, 1, 3, 3]),\\\n",
    "    \"For percentile 0 you should return all states and actions in chronological order\"\n",
    "assert np.all(test_result_40[0] == [4, 2, 0, 2, 3, 1]) and \\\n",
    "    np.all(test_result_40[1] == [3, 2, 0, 1, 3, 3]),\\\n",
    "    \"For percentile 30 you should only select states/actions from two first\"\n",
    "assert np.all(test_result_90[0] == [3, 1]) and \\\n",
    "    np.all(test_result_90[1] == [3, 3]),\\\n",
    "    \"For percentile 90 you should only select states/actions from one game\"\n",
    "assert np.all(test_result_100[0] == [3, 1]) and\\\n",
    "    np.all(test_result_100[1] == [3, 3]),\\\n",
    "    \"Please make sure you use >=, not >. Also double-check how you compute percentile.\"\n",
    "print(\"Ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agent\n",
    "\n",
    "def get_agent(env, n_actions):\n",
    "    agent = MLPClassifier(hidden_layer_sizes=(20, 20),\n",
    "                          activation='tanh',\n",
    "                          warm_start=True,  # keep progress between .fit(...) calls\n",
    "                          max_iter=1  # make only 1 iteration on each .fit(...)\n",
    "                          )\n",
    "    # initialize agent to the dimension of state an amount of actions\n",
    "    agent.fit([env.reset()]*n_actions, range(n_actions))\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(env, agent, t_max=1000):\n",
    "\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        # predict array of action probabilities\n",
    "        probs = agent.predict_proba([s])[0]\n",
    "        # print(probs)\n",
    "\n",
    "        a = np.random.choice(len(probs), p=probs)\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, agent, iters=1000, treshold=200, n_sessions=100, percentile=70, t_max=1000):\n",
    "    log = []\n",
    "\n",
    "    for i in range(iters):\n",
    "        # generate new sessions\n",
    "        # sessions = [ < generate a list of n_sessions new sessions > ]\n",
    "        %time\n",
    "        sessions = [generate_session(env, agent, t_max=t_max) for i in range(n_sessions)]\n",
    "\n",
    "        states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "        # elite_states, elite_actions = <select elite actions just like before >\n",
    "        # <fit agent to predict elite_actions(y) from elite_states(X) >\n",
    "\n",
    "        elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "        agent.fit(elite_states, elite_actions)\n",
    "\n",
    "        show_progress(rewards_batch, log, reward_range=[np.min(rewards_batch), np.max(rewards_batch)], percentile=percentile)\n",
    "\n",
    "        if np.mean(rewards_batch) > treshold:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "def solve(name, iters=100, treshold=200, n_sessions=100, percentile=70, t_max=1000):\n",
    "    env = gym.make(name).env\n",
    "    env.reset()\n",
    "    n_actions = env.action_space.n\n",
    "    \n",
    "    agent = get_agent(env, n_actions)\n",
    "    \n",
    "    train(env, agent, iters=iters, treshold=treshold, n_sessions=n_sessions, percentile=percentile, t_max=t_max)\n",
    "\n",
    "    return agent\n",
    "    # plt.imshow(env.render(\"rgb_array\"))\n",
    "    # env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record sessions\n",
    "def show(name, agent, t_max=1000):\n",
    "    env = gym.wrappers.Monitor(gym.make(name), directory=\"videos\", force=True)\n",
    "    sessions = [generate_session(env, agent, t_max=t_max) for _ in range(100)]\n",
    "    env.close()\n",
    "    return env\n",
    "# upload to gym\n",
    "# gym.upload(\"./videos/\",api_key=\"<your_api_key>\") #you'll need me later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, t, t_max = \"CartPole-v0\", 200, 1000\n",
    "# name, t, t_max = \"MountainCar-v0\", -150, 10000\n",
    "# name, t, t_max = \"LunarLander-v2\", 50, 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = -148.700, threshold=-121.000\n"
     ]
    }
   ],
   "source": [
    "agent = solve(name, treshold=t, n_sessions=200, percentile=70, t_max=t_max)\n",
    "\n",
    "import pickle\n",
    "if not os.path.exists('tmp'):\n",
    "    os.mkdir('tmp')\n",
    "with open('tmp/' + name + '.pkl', 'wb') as model_file:\n",
    "    pickle.dump(agent, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CartPole-v0.pkl  LunarLander-v2-my.pkl\tLunarLander-v2.pkl  MountainCar-v0.pkl\n",
      "tmp/CartPole-v0.pkl\n"
     ]
    }
   ],
   "source": [
    "! ls tmp\n",
    "\n",
    "filename = 'tmp/' + name + '.pkl'\n",
    "with open(filename, 'rb') as model_file:\n",
    "    agent = pickle.load(model_file)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = show(name, agent, t_max=t_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./videos/openaigym.video.7.7879.video000008.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show video\n",
    "\n",
    "video_names = list(\n",
    "    filter(lambda s: s.endswith(\".mp4\"), os.listdir(\"./videos/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./videos/\"+video_names[1]))  # this may or may not be _last_ video. Try other indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part I\n",
    "\n",
    "### Tabular crossentropy method\n",
    "\n",
    "You may have noticed that the taxi problem quickly converges from -100 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
    "\n",
    "### Tasks\n",
    "- __1.1__ (1 pts) Find out how the algorithm performance changes if you change different percentile and different n_samples.\n",
    "- __1.2__ (2 pts) Tune the algorithm to end up with positive average score.\n",
    "\n",
    "It's okay to modify the existing code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```<Describe what you did here.  Preferably with plot/report to support it.>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part II\n",
    "\n",
    "### Deep crossentropy method\n",
    "\n",
    "By this moment you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to upload the result and get to something harder.\n",
    "\n",
    "* if you have any trouble with CartPole-v0 and feel stuck, feel free to ask us or your peers for help.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* __2.1__ (3 pts) Pick one of environments: MountainCar-v0 or LunarLander-v2.\n",
    "  * For MountainCar, get average reward of __at least -150__\n",
    "  * For LunarLander, get average reward of __at least +50__\n",
    "  * For any environment, upload it to gym and post url in your anytask form.\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "__Note:__ If your agent is below the target score, you'll still get most of the points depending on the result, so don't be afraid to submit it.\n",
    "  \n",
    "  \n",
    "* __2.2__ (bonus: 4++ pt) Devise a way to speed up training at least 2x against the default version\n",
    "  * Obvious improvement: use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training\n",
    "  * Experiment with amount of training iterations and learning rate of the neural network (see params)\n",
    "  * __Please list what you did in anytask submission form__\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gym page: [mountaincar](https://gym.openai.com/envs/MountainCar-v0), [lunarlander](https://gym.openai.com/envs/LunarLander-v2)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 20% are better, than if you use percentile 20% as threshold, R >= threshold __fails cut off bad sessions__ whule R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If you use old _swig_ lib for LunarLander-v2, you may get an error. See this [issue](https://github.com/openai/gym/issues/100) for solution.\n",
    "* If it won't train it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "* __Please upload the results to openai gym and send links to all submissions in the e-mail__\n",
    "\n",
    "### Bonus tasks\n",
    "\n",
    "* __2.3 bonus__ Try to find a network architecture and training params that solve __both__ environments above (_Points depend on implementation. If you attempted this task, please mention it in anytask submission._)\n",
    "\n",
    "* __2.4 bonus__ Solve continuous action space task with `MLPRegressor` or similar.\n",
    "  * Start with [\"Pendulum-v0\"](https://github.com/openai/gym/wiki/Pendulum-v0).\n",
    "  * Since your agent only predicts the \"expected\" action, you will have to add noise to ensure exploration.\n",
    "  * [MountainCarContinuous-v0](https://gym.openai.com/envs/MountainCarContinuous-v0), [LunarLanderContinuous-v2](https://gym.openai.com/envs/LunarLanderContinuous-v2) \n",
    "  * 4 points for solving. Slightly less for getting some results below solution threshold. Note that discrete and continuous environments may have slightly different rules aside from action spaces.\n",
    "\n",
    "\n",
    "If you're still feeling unchallenged, consider the project (see other notebook in this folder)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
